{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Pipe Failure Conditions with Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- pymssql\\n- pandas\\n- json\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dependancies list\n",
    "'''\n",
    "- pymssql\n",
    "- pandas\n",
    "- json\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Importing Data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pypyodbc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b7e2b7c2a192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpypyodbc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpypyodbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DRIVER={SQL Server};                        SERVER=yvwchallenge.chqn5g6ohkqb.ap-southeast-2.rds.amazonaws.com;                        UID=admin;                        PWD=passwordpassword;                        DATABASE=yvwchallenge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pypyodbc'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pypyodbc\n",
    "\n",
    "conn = pypyodbc.connect(\"DRIVER={SQL Server};\\\n",
    "                        SERVER={Add Server}\\\n",
    "                        UID={user};\\\n",
    "                        PWD={pword};\\\n",
    "                        DATABASE={DBname}\")\n",
    "#data[\"title\"] = data.boilerplate.map(lambda x: json.loads(x).get(\"title\", \"\"))\n",
    "#data[\"body\"] = data.boilerplate.map(lambda x: json.loads(x).get(\"body\", \"\"))\n",
    "#data = pd.read_sql(data_sql)\n",
    "\n",
    "yvw_df = pd.read_sql('SELECT * FROM yvwdataframe_firstbreak', conn)\n",
    "yvw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yvw_df[[\"failure description\"]].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvw_df.to_pickle(\"yvw_df_firstbreak.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvw_df = pd.read_pickle(\"yvw_df_firstbreak.pkl\")\n",
    "yvw_df = pd.DataFrame(yvw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yvw_df.groupby([\"description\"])[[\"asset id\"]].count())\n",
    "print(yvw_df.groupby([\"nominal size (mm)\"])[[\"asset id\"]].count())\n",
    "print(yvw_df[\"failure description\"].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import defaultdict\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "fit = yvw_df.apply(lambda x: d[x.name].fit_transform(x))\n",
    "yvw_df = yvw_df.reindex()\n",
    "#yvw_df.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "X = fit.dropna()\n",
    "y = X['months_break']\n",
    "X.drop('months_break', axis = 1, inplace = True)  \n",
    "\n",
    "fit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fits the model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Helper function to visualise Decision Trees (creates a file tree.png)\n",
    "from sklearn.tree import export_graphviz\n",
    "from os import system\n",
    "\n",
    "def build_tree_image(model):\n",
    "    dotfile = open(\"tree.dot\", \"w\")\n",
    "    export_graphviz(model,\n",
    "                    out_file = dotfile,\n",
    "                    feature_names = X.columns)\n",
    "    dotfile.close()\n",
    "    system(\"dot -Tpng tree.dot -o tree.png\")\n",
    "build_tree_image(model)\n",
    "    \n",
    "model\n",
    "scores = cross_val_score(model, X, y, cv = 40)\n",
    "print(\"CV AUC {}, Average AUC {}\",scores, scores.mean(), scores.max())\n",
    "#20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yvw_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classification\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "seed = 7\n",
    "num_trees = 200\n",
    "max_features = 15\n",
    "kfold = model_selection.KFold(n_splits=20, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features, n_jobs=-1)\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 5)\n",
    "#model.fit(X, y)\n",
    "#build_tree_image(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  random forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100, n_jobs=-1)    \n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "features_df = pd.DataFrame({\"Features\": features, \"Importance Score\": feature_importances})\n",
    "features_df.sort_values(\"Importance Score\", inplace = True, ascending = False)\n",
    "\n",
    "features_df.head()\n",
    "print(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval the Random Forest model using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring = \"roc_auc\")\n",
    "print(\"CV AUC {}, Average AUC {}\".format(scores, scores.mean()))\n",
    "\n",
    "for n_trees in range(1, 100, 10):\n",
    "    model = RandomForestClassifier(n_estimators = n_trees)\n",
    "    scores = cross_val_score(model, X, y)\n",
    "    print(\"n trees: {}, CV AUC {}, Average AUC {}\", n_trees, scores, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Building a model with more relevant features\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "# Continue to add features to X\n",
    "#     Build dummy features, include quantitative features, or add text features\n",
    "X = data[[\"image_ratio\", \"html_ratio\", \"recipe\", \"label\"]].dropna()\n",
    "y = X[\"label\"]\n",
    "X.drop(\"label\", axis = 1, inplace = True)\n",
    "\n",
    "## 2a. Evaluate predictive performance for the given feature set\n",
    "scores = cross_val_score(model, X, y, scoring = \"roc_auc\")\n",
    "print(\"CV AUC {}, Average AUC {}\".format(scores, scores.mean()))\n",
    "\n",
    "# 3 (BONUS): Adding in text features\n",
    "\n",
    "# Check for keywords in the title\n",
    "data[\"PhotoInTitle\"] = data[\"title\"].fillna(\"\").str.lower().str.contains(\"photo\").astype(int)\n",
    "X = data[[\"image_ratio\", \"html_ratio\", \"recipe\", \"PhotoInTitle\", \"label\"]].dropna()\n",
    "X.drop(\"label\", axis = 1, inplace = True)\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring = \"roc_auc\")\n",
    "print(\"CV AUC {}, Average AUC {}\".format(scores, scores.mean()))\n",
    "\n",
    "## 2b. Evaluating feature importances\n",
    "\n",
    "# Fit a model on the whole dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get columns and their scores\n",
    "features = X.columns\n",
    "feature_importances = model.feature_importances_\n",
    "features_df = pd.DataFrame({\"Features\": features, \"Importance Score\": feature_importances})\n",
    "features_df.sort_values(\"Importance Score\", inplace = True, ascending = False)\n",
    "\n",
    "features_df.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
